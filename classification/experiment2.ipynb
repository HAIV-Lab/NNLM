{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from model import MyModel\n",
    "from build import build_dataset\n",
    "from dataset import PrefixDataset1\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--lr', type=float, default=0.0003, help='Learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='train epochs')\n",
    "    parser.add_argument('--milestones', type=int, nargs='+', default=[116, 233], help='Milestones')\n",
    "    parser.add_argument('--gamma', type=float, default=0.1, help='Gamma')\n",
    "    # parser.add_argument('--optimizer', type=str, default='sgd', help='optimizer')\n",
    "\n",
    "    parser.add_argument('--voc_len',type=int, default=42020, help='voc number')\n",
    "    parser.add_argument('--embedding_dim',type=int, default=1024, help='embedding size')\n",
    "    parser.add_argument('--output_dim', type=int, default=64, help=\"output dim\")\n",
    "    parser.add_argument('--dstore_mmap',type=str, default='/data/zqh/NLP/adaptive-knn-mt/store/datastore/it_finetune')\n",
    "    parser.add_argument('--dstore_size',type=int, default=3608731, help='datastore size')\n",
    "    parser.add_argument('--use_cluster', type=bool, default=True, help=\"if use word cluster\")\n",
    "    parser.add_argument('--cluster_type', type=str, default='spectrum', help='cluster type')\n",
    "    \n",
    "    # contrastive learning\n",
    "    parser.add_argument('--K', type=int, default=500, help='queue size')\n",
    "    parser.add_argument('--m', type=float, default=0.999, help='momentum')\n",
    "    parser.add_argument('--class_num', type=int, default=42020, help=\"class number\")\n",
    "    \n",
    "\n",
    "    # save\n",
    "    parser.add_argument('--save_path', type=str, default='/data/zqh/adaptive-knn-mt/checkpoints/koran', help='save checkpoint dir')\n",
    "    # dataset\n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "dataset= PrefixDataset1(args=args)\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "import math\n",
    "\n",
    "choice_label = np.arange(args.voc_len)\n",
    "np.random.shuffle(choice_label)\n",
    "\n",
    "real_choice_label = []\n",
    "for i in choice_label:\n",
    "    if len(dataset.label[dataset.label==i]) >= 200:\n",
    "        real_choice_label.append(i)\n",
    "    if len(real_choice_label) == 2:\n",
    "        break\n",
    "\n",
    "labels = None\n",
    "embedding = None\n",
    "for j, i in enumerate(real_choice_label):\n",
    "    temp_embedding = dataset.data[dataset.label==i]\n",
    "    temp_labels = dataset.label[dataset.label==i]\n",
    "    choice_sample = np.arange(temp_embedding.shape[0])\n",
    "    np.random.shuffle(choice_sample)\n",
    "    number = min(200, temp_embedding.shape[0])\n",
    "    choice_sample = choice_sample[:]\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = np.full(choice_sample.shape, j) \n",
    "        embedding = temp_embedding[choice_sample]\n",
    "    else:\n",
    "        labels = np.concatenate((labels, np.full(choice_sample.shape, j)))\n",
    "        embedding = np.concatenate((embedding, temp_embedding[choice_sample]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne_embedding = tsne.fit_transform(embedding)\n",
    "plt.scatter(tsne_embedding[:,0], \n",
    "tsne_embedding[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.data = embedding\n",
    "        self.labels = labels\n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        embedding = self.data[index]\n",
    "        pos_index = None\n",
    "        for i, label in enumerate(self.labels):\n",
    "            if label == self.labels[index]:\n",
    "                pos_index = i\n",
    "                break\n",
    "        embedding_1 = self.data[pos_index]\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return embedding, embedding_1, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mymodel = MyModel(args).cuda()\n",
    "\n",
    "dataset = EmbeddingDataset(args)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset = dataset,\n",
    "    batch_size = args.batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(mymodel.parameters(), args.lr, \n",
    "                                         momentum=0.9, nesterov=True,\n",
    "                                         weight_decay=0.0004)\n",
    "# self.optimizer = optim.FP16Optimizer.build_optimizer(self.args, params)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.milestones, gamma=args.gamma)\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    correct = 0\n",
    "    data_len = 0\n",
    "    for i, (x, x_key, label) in enumerate(dataloader):\n",
    "        x = x.cuda()\n",
    "        x_key = x_key.cuda()\n",
    "        label = label.cuda().long()\n",
    "\n",
    "        logits, loss, _, _ = mymodel(x, x_key, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predictions = logits.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            batch_correct = predictions.eq(label.view_as(predictions)).sum().item()\n",
    "            acc = batch_correct / x.shape[0]\n",
    "\n",
    "            print(f\"Train epoch: {epoch} loss: {loss} acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "con_embedding = None\n",
    "con_label = None\n",
    "for i, (x, x_key, label) in enumerate(dataloader):\n",
    "    x = x.cuda()\n",
    "    hidden = mymodel.encode(x)\n",
    "    if con_embedding is None:\n",
    "        con_embedding = hidden\n",
    "        con_label = label\n",
    "    else:\n",
    "        con_embedding = torch.cat((con_embedding, hidden))\n",
    "        con_label = torch.cat((con_label, label))\n",
    "con_embedding = con_embedding.cpu().detach().numpy()\n",
    "con_label = con_label.cpu().detach().numpy()\n",
    "\n",
    "tsne_embedding = tsne.fit_transform(con_embedding)\n",
    "plt.scatter(tsne_embedding[:,0], \n",
    "tsne_embedding[:,1], c=con_label)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('adaptive-knn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a486ca640bf467f84ac38103d0adf31508c8d9bebf3e22116d5da9069abbb3a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
